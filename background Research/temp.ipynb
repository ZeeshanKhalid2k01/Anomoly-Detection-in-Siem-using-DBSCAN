{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import joblib\n",
    "\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "# Disable the warning about unverified HTTPS requests\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "# Set INITIAL TIME & END TIME\n",
    "INITIAL_TIME = 0\n",
    "END_TIME = 0\n",
    "\n",
    "# Set ELASTICSEARCH_URL, ES_USERNAME, ES_PASSWORD\n",
    "ELASTICSEARCH_URL = \"https://192.168.7.2:9200\"\n",
    "ES_USERNAME = \"elastic\"\n",
    "ES_PASSWORD = \"ncsael@123\"\n",
    "INDEX_NAME = \"siem-*\"\n",
    "\n",
    "# orignal dataframe\n",
    "DF=pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def reset_time():\n",
    "#     global INITIAL_TIME\n",
    "#     global END_TIME\n",
    "    \n",
    "#     if(INITIAL_TIME != 0):\n",
    "#         INITIAL_TIME = END_TIME\n",
    "\n",
    "#     else:\n",
    "#         last_timestamp = datetime.utcnow() - timedelta(minutes=2)\n",
    "#         INITIAL_TIME = last_timestamp.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    \n",
    "#     current_time = datetime.utcnow()\n",
    "#     END_TIME = current_time.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "\n",
    "# reset_time()\n",
    "# print(INITIAL_TIME)\n",
    "# print(END_TIME)\n",
    "\n",
    "# def find_hits():\n",
    "#     global INITIAL_TIME\n",
    "#     global END_TIME\n",
    "#     global ELASTICSEARCH_URL\n",
    "#     global ES_USERNAME\n",
    "#     global ES_PASSWORD\n",
    "\n",
    "#     url = f\"{ELASTICSEARCH_URL}/siem-*/_search\"\n",
    "#     headers = {\n",
    "#         \"Content-Type\": \"application/json\"\n",
    "#     }\n",
    "#     payload = {\n",
    "#         \"query\": {\n",
    "#             \"range\": {\n",
    "#                 \"@timestamp\": {\n",
    "#                     \"gte\": INITIAL_TIME,\n",
    "#                     \"lte\": END_TIME\n",
    "#                 }\n",
    "#             }\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "#     try:\n",
    "#         response = requests.get(url, auth=(ES_USERNAME, ES_PASSWORD), headers=headers, json=payload, verify=False)\n",
    "#         if response.status_code == 200:\n",
    "#             logs = response.json()\n",
    "#             total_logs = logs[\"hits\"][\"total\"][\"value\"] if \"hits\" in logs else 0\n",
    "#             # print(f\"Total new logs since {INITIAL_TIME}: {total_logs}\")\n",
    "#             return total_logs\n",
    "#         else:\n",
    "#             print(\"Failed to fetch logs.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to connect: {e}\")\n",
    "\n",
    "# # print(find_hits())\n",
    "\n",
    "# def add_data(hits):\n",
    "#     global INITIAL_TIME\n",
    "#     global END_TIME\n",
    "#     global ELASTICSEARCH_URL\n",
    "#     global ES_USERNAME\n",
    "#     global ES_PASSWORD\n",
    "#     global INDEX_NAME\n",
    "\n",
    "#     url = f\"{ELASTICSEARCH_URL}/{INDEX_NAME}/_search\"\n",
    "#     headers = {\n",
    "#         \"Content-Type\": \"application/json\"\n",
    "#     }\n",
    "#     payload = {\n",
    "#         \"sort\": [\n",
    "#             {\n",
    "#                 \"@timestamp\": {\n",
    "#                     \"order\": \"desc\",\n",
    "#                     \"format\": \"strict_date_optional_time\",\n",
    "#                     \"unmapped_type\": \"boolean\"\n",
    "#                 }\n",
    "#             },\n",
    "#             {\n",
    "#                 \"_doc\": {\n",
    "#                     \"order\": \"desc\",\n",
    "#                     \"unmapped_type\": \"boolean\"\n",
    "#                 }\n",
    "#             }\n",
    "#         ],\n",
    "#         \"track_total_hits\": False,\n",
    "#         \"fields\": [\n",
    "#             {\n",
    "#                 \"field\": \"*\",\n",
    "#                 \"include_unmapped\": \"true\"\n",
    "#             },\n",
    "#             {\n",
    "#                 \"field\": \"@timestamp\",\n",
    "#                 \"format\": \"strict_date_optional_time\"\n",
    "#             },\n",
    "#             {\n",
    "#                 \"field\": \"BeginTime\",\n",
    "#                 \"format\": \"strict_date_optional_time\"\n",
    "#             },\n",
    "#             {\n",
    "#                 \"field\": \"EndTime\",\n",
    "#                 \"format\": \"strict_date_optional_time\"\n",
    "#             },\n",
    "#             {\n",
    "#                 \"field\": \"Time\",\n",
    "#                 \"format\": \"strict_date_optional_time\"\n",
    "#             }\n",
    "#         ],\n",
    "#         \"size\": hits,\n",
    "#         \"version\": True,\n",
    "#         \"script_fields\": {},\n",
    "#         \"stored_fields\": [\"*\"],\n",
    "#         \"runtime_mappings\": {},\n",
    "#         \"_source\": False,\n",
    "#         \"query\": {\n",
    "#             \"bool\": {\n",
    "#                 \"must\": [],\n",
    "#                 \"filter\": [\n",
    "#                     {\n",
    "#                         \"range\": {\n",
    "#                             \"@timestamp\": {\n",
    "#                                 \"format\": \"strict_date_optional_time\",\n",
    "#                                 \"gte\": INITIAL_TIME,\n",
    "#                                 \"lte\": END_TIME\n",
    "#                             }\n",
    "#                         }\n",
    "#                     }\n",
    "#                 ],\n",
    "#                 \"should\": [],\n",
    "#                 \"must_not\": []\n",
    "#             }\n",
    "#         },\n",
    "#         \"highlight\": {\n",
    "#             \"pre_tags\": [\"@kibana-highlighted-field@\"],\n",
    "#             \"post_tags\": [\"@/kibana-highlighted-field@\"],\n",
    "#             \"fields\": {\"*\": {}},\n",
    "#             \"fragment_size\": 2147483647\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "#     response = requests.get(url, auth=(ES_USERNAME, ES_PASSWORD), headers=headers, json=payload, verify=False)\n",
    "    \n",
    "    \n",
    "#     if response.status_code == 200:\n",
    "#         return response.json()\n",
    "#     else:\n",
    "#         return {\"error\": \"Failed to fetch logs.\"}\n",
    "\n",
    "# # Call the function to fetch logs\n",
    "# logs = add_data(find_hits())\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# # Check if logs were fetched successfully\n",
    "# if \"error\" not in logs:\n",
    "#     hits = logs.get(\"hits\", {}).get(\"hits\", [])\n",
    "    \n",
    "#     # Extracting fields from hits\n",
    "#     data = [hit.get(\"fields\", {}) for hit in hits]\n",
    "\n",
    "#     # Create DataFrame\n",
    "#     df_logs = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def clean_data(df_logs):\n",
    "#     # check for req\n",
    "#     required_columns = [\n",
    "#         \"@timestamp\", \"Action\", \"Application\", \"Attack\", \"BeginTime\", \"Category\", \"CloseReason\", \"Cpu\",\n",
    "#         \"Destination-address\", \"Destination-port\", \"Destination-vpn-id\", \"Destination-zone\", \"DstLocation\",\n",
    "#         \"EndTime\", \"EventNum\", \"IP-address\", \"IPVer\", \"MaxSpeed\", \"ModuleBrief\", \"ModuleName\", \"Os\", \"Policy\",\n",
    "#         \"Policy-name\", \"Priority\", \"Profile\", \"Protocol-Name\", \"Protocol-Number\", \"RcvBytes\", \"RcvPkts\",\n",
    "#         \"RecieveInterface\", \"Role\", \"SendBytes\", \"SendPkts\", \"Severity\", \"SignId\", \"SignName\", \"Source-address\",\n",
    "#         \"Source-vpn-id\", \"Source-zone\", \"SrcLocation\", \"SyslogId\", \"Target\", \"TotalPackets\", \"UserName\", \"VSys\", \"slot\"\n",
    "#     ]\n",
    "    \n",
    "#     missing_columns = [col for col in required_columns if col not in df_logs.columns]\n",
    "\n",
    "#     if missing_columns:\n",
    "#         print(f\"The following columns are missing: {', '.join(missing_columns)}\")\n",
    "        \n",
    "#         # Add missing columns with NaN values to the DataFrame\n",
    "#         for col in missing_columns:\n",
    "#             df_logs[col] = pd.NA  # or df_logs[col] = None for older Pandas versions\n",
    "    \n",
    "#     else:\n",
    "#         print(\"All required columns are present in the DataFrame.\")\n",
    "\n",
    "# # Example usage\n",
    "# # Assuming df_logs is your DataFrame\n",
    "# # clean_data(df_logs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_time_values():\n",
    "\n",
    "    global DF\n",
    "    \n",
    "    # def reset_time():\n",
    "    #     global INITIAL_TIME\n",
    "    #     global END_TIME\n",
    "        \n",
    "    #     if(INITIAL_TIME != 0):\n",
    "    #         INITIAL_TIME = END_TIME\n",
    "\n",
    "    #     else:\n",
    "    #         last_timestamp = datetime.utcnow() - timedelta(minutes=2)\n",
    "    #         INITIAL_TIME = last_timestamp.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        \n",
    "    #     current_time = datetime.utcnow()\n",
    "    #     END_TIME = current_time.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "\n",
    "    # reset_time()\n",
    "    # print(INITIAL_TIME)\n",
    "    # print(END_TIME)\n",
    "\n",
    "    def reset_time():\n",
    "        global INITIAL_TIME\n",
    "        global END_TIME\n",
    "        log_file = \"time_log.txt\"  # File to store start and end times\n",
    "\n",
    "        if os.path.exists(log_file):\n",
    "            # Read the last recorded end time from the log file\n",
    "            with open(log_file, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "                last_end_time = lines[-1].strip() if lines else None\n",
    "\n",
    "            if last_end_time:\n",
    "                start_time = datetime.strptime(last_end_time, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "            else:\n",
    "                start_time = datetime.utcnow() - timedelta(minutes=2)\n",
    "        else:\n",
    "            start_time = datetime.utcnow() - timedelta(minutes=2)\n",
    "\n",
    "        end_time = start_time + timedelta(minutes=2)\n",
    "\n",
    "        # Store the end time in the log file for future reference\n",
    "        with open(log_file, 'a') as file:\n",
    "            file.write(end_time.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\") + \"\\n\")\n",
    "\n",
    "        INITIAL_TIME = start_time.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        END_TIME = end_time.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "\n",
    "    reset_time()    \n",
    "\n",
    "\n",
    "\n",
    "    def find_hits():\n",
    "        global INITIAL_TIME\n",
    "        global END_TIME\n",
    "        global ELASTICSEARCH_URL\n",
    "        global ES_USERNAME\n",
    "        global ES_PASSWORD\n",
    "\n",
    "        url = f\"{ELASTICSEARCH_URL}/siem-*/_search\"\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        payload = {\n",
    "            \"query\": {\n",
    "                \"range\": {\n",
    "                    \"@timestamp\": {\n",
    "                        \"gte\": INITIAL_TIME,\n",
    "                        \"lte\": END_TIME\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, auth=(ES_USERNAME, ES_PASSWORD), headers=headers, json=payload, verify=False)\n",
    "            if response.status_code == 200:\n",
    "                logs = response.json()\n",
    "                total_logs = logs[\"hits\"][\"total\"][\"value\"] if \"hits\" in logs else 0\n",
    "                # print(f\"Total new logs since {INITIAL_TIME}: {total_logs}\")\n",
    "                return total_logs\n",
    "            else:\n",
    "                print(\"Failed to fetch logs.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to connect: {e}\")\n",
    "\n",
    "    # print(find_hits())\n",
    "\n",
    "    def add_data(hits):\n",
    "        global INITIAL_TIME\n",
    "        global END_TIME\n",
    "        global ELASTICSEARCH_URL\n",
    "        global ES_USERNAME\n",
    "        global ES_PASSWORD\n",
    "        global INDEX_NAME\n",
    "\n",
    "        url = f\"{ELASTICSEARCH_URL}/{INDEX_NAME}/_search\"\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        payload = {\n",
    "            \"sort\": [\n",
    "                {\n",
    "                    \"@timestamp\": {\n",
    "                        \"order\": \"desc\",\n",
    "                        \"format\": \"strict_date_optional_time\",\n",
    "                        \"unmapped_type\": \"boolean\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"_doc\": {\n",
    "                        \"order\": \"desc\",\n",
    "                        \"unmapped_type\": \"boolean\"\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            \"track_total_hits\": False,\n",
    "            \"fields\": [\n",
    "                {\n",
    "                    \"field\": \"*\",\n",
    "                    \"include_unmapped\": \"true\"\n",
    "                },\n",
    "                {\n",
    "                    \"field\": \"@timestamp\",\n",
    "                    \"format\": \"strict_date_optional_time\"\n",
    "                },\n",
    "                {\n",
    "                    \"field\": \"BeginTime\",\n",
    "                    \"format\": \"strict_date_optional_time\"\n",
    "                },\n",
    "                {\n",
    "                    \"field\": \"EndTime\",\n",
    "                    \"format\": \"strict_date_optional_time\"\n",
    "                },\n",
    "                {\n",
    "                    \"field\": \"Time\",\n",
    "                    \"format\": \"strict_date_optional_time\"\n",
    "                }\n",
    "            ],\n",
    "            \"size\": hits,\n",
    "            \"version\": True,\n",
    "            \"script_fields\": {},\n",
    "            \"stored_fields\": [\"*\"],\n",
    "            \"runtime_mappings\": {},\n",
    "            \"_source\": False,\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"must\": [],\n",
    "                    \"filter\": [\n",
    "                        {\n",
    "                            \"range\": {\n",
    "                                \"@timestamp\": {\n",
    "                                    \"format\": \"strict_date_optional_time\",\n",
    "                                    \"gte\": INITIAL_TIME,\n",
    "                                    \"lte\": END_TIME\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    ],\n",
    "                    \"should\": [],\n",
    "                    \"must_not\": []\n",
    "                }\n",
    "            },\n",
    "            \"highlight\": {\n",
    "                \"pre_tags\": [\"@kibana-highlighted-field@\"],\n",
    "                \"post_tags\": [\"@/kibana-highlighted-field@\"],\n",
    "                \"fields\": {\"*\": {}},\n",
    "                \"fragment_size\": 2147483647\n",
    "            }\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, auth=(ES_USERNAME, ES_PASSWORD), headers=headers, json=payload, verify=False)\n",
    "        \n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            return {\"error\": \"Failed to fetch logs.\"}\n",
    "\n",
    "    # Call the function to fetch logs\n",
    "    logs = add_data(find_hits())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    # Check if logs were fetched successfully\n",
    "    if \"error\" not in logs:\n",
    "        hits = logs.get(\"hits\", {}).get(\"hits\", [])\n",
    "        \n",
    "        # Extracting fields from hits\n",
    "        # data = [hit.get(\"fields\", {}) for hit in hits]\n",
    "        data = [{\"_id\": hit.get(\"_id\"), **hit.get(\"fields\", {})} for hit in hits]\n",
    "\n",
    "\n",
    "        # Create DataFrame\n",
    "        df_logs = pd.DataFrame(data)\n",
    "        DF = df_logs.copy()\n",
    "        return df_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db():\n",
    "    #check if seam_logs.db exist or not\n",
    "    if os.path.exists('seam_logs.db'):\n",
    "        print(\"Database already exists.\")\n",
    "    else:\n",
    "        print(\"Creating database...\")\n",
    "        import sqlite3\n",
    "\n",
    "        # Connect to a database (will create a new one if it doesn't exist)\n",
    "        conn = sqlite3.connect('seam_logs.db')\n",
    "\n",
    "        # Create a cursor object to execute SQL commands\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # SQL command to create a table\n",
    "        create_table_query = '''\n",
    "        CREATE TABLE IF NOT EXISTS seam_table (\n",
    "            Action INTEGER,\n",
    "            Application INTEGER,\n",
    "            Attack INTEGER,\n",
    "            Category INTEGER,\n",
    "            CloseReason INTEGER,\n",
    "            Cpu REAL,\n",
    "            \"Destination-address\" INTEGER,\n",
    "            \"Destination-port\" REAL,\n",
    "            \"Destination-vpn-id\" REAL,\n",
    "            \"Destination-zone\" INTEGER,\n",
    "            DstLocation INTEGER,\n",
    "            EventNum REAL,\n",
    "            \"IP-address\" INTEGER,\n",
    "            IPVer REAL,\n",
    "            MaxSpeed REAL,\n",
    "            ModuleBrief INTEGER,\n",
    "            ModuleName INTEGER,\n",
    "            Os INTEGER,\n",
    "            Policy INTEGER,\n",
    "            \"Policy-name\" INTEGER,\n",
    "            Priority TEXT,\n",
    "            Profile INTEGER,\n",
    "            \"Protocol-Name\" INTEGER,\n",
    "            \"Protocol-Number\" REAL,\n",
    "            RcvBytes INTEGER,\n",
    "            RcvPkts INTEGER,\n",
    "            RecieveInterface INTEGER,\n",
    "            Role REAL,\n",
    "            SendBytes INTEGER,\n",
    "            SendPkts INTEGER,\n",
    "            Severity TEXT,\n",
    "            SignId REAL,\n",
    "            SignName INTEGER,\n",
    "            \"Source-address\" INTEGER,\n",
    "            \"Source-vpn-id\" REAL,\n",
    "            \"Source-zone\" INTEGER,\n",
    "            SrcLocation INTEGER,\n",
    "            SyslogId INTEGER,\n",
    "            Target INTEGER,\n",
    "            TotalPackets REAL,\n",
    "            UserName INTEGER,\n",
    "            VSys INTEGER,\n",
    "            slot INTEGER,\n",
    "            Processed REAL,\n",
    "            DayOfTheWeek INTEGER,\n",
    "            DayOrNight INTEGER,\n",
    "            TimeBins INTEGER\n",
    "        );\n",
    "        '''\n",
    "\n",
    "        # Execute the SQL command to create the table\n",
    "        cursor.execute(create_table_query)\n",
    "\n",
    "        # Commit changes and close connection\n",
    "        conn.commit()\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_required_cols(df_logs):\n",
    "    # Assuming df_logs is your DataFrame\n",
    "    required_columns = [\n",
    "        \"@timestamp\", \"Action\", \"Application\", \"Attack\", \"BeginTime\", \"Category\", \"CloseReason\", \"Cpu\",\n",
    "        \"Destination-address\", \"Destination-port\", \"Destination-vpn-id\", \"Destination-zone\", \"DstLocation\",\n",
    "        \"EndTime\", \"EventNum\", \"IPVer\", \"MaxSpeed\", \"ModuleBrief\", \"ModuleName\", \"Os\", \"Policy\",\n",
    "        \"Policy-name\", \"Priority\", \"Profile\", \"Protocol-Name\", \"Protocol-Number\", \"RcvBytes\", \"RcvPkts\",\n",
    "        \"RecieveInterface\", \"Role\", \"SendBytes\", \"SendPkts\", \"Severity\", \"SignId\", \"SignName\", \"Source-address\",\n",
    "        \"Source-vpn-id\", \"Source-zone\", \"SrcLocation\", \"SyslogId\", \"Target\", \"TotalPackets\", \"UserName\", \"VSys\", \"slot\"\n",
    "    ]\n",
    "\n",
    "    missing_columns = [col for col in required_columns if col not in df_logs.columns]\n",
    "\n",
    "    if missing_columns:\n",
    "        print(f\"The following columns are missing: {', '.join(missing_columns)}\")\n",
    "\n",
    "        # Add missing columns with NaN values to the DataFrame\n",
    "        for col in missing_columns:\n",
    "            df_logs[col] = np.nan\n",
    "\n",
    "        df_logs = df_logs[required_columns]\n",
    "    else:\n",
    "        print(\"All required columns are present in the DataFrame.\")\n",
    "        df_logs = df_logs[required_columns]\n",
    "    \n",
    "    return df_logs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_value_special_symbols(value):\n",
    "    return str(value).replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace(\"nan\", \"-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# import pickle\n",
    "\n",
    "# def label_encoding(df_logs):\n",
    "#     # Map of column-wise label encoders\n",
    "#     label_encoders = {}\n",
    "    \n",
    "#     # Load existing label mappings or create an empty one\n",
    "#     try:\n",
    "#         with open('label_mapping.pkl', 'rb') as f:\n",
    "#             label_mapping = pickle.load(f)\n",
    "#     except FileNotFoundError:\n",
    "#         label_mapping = {}\n",
    "\n",
    "#     cols_to_encode = [\n",
    "#         'Attack', 'Category', 'DstLocation', 'Os', 'SignName', 'SrcLocation', 'Target',\n",
    "#         'UserName', 'VSys', 'slot', 'Action', 'Policy', 'Profile', 'Protocol-Name',\n",
    "#         'Application', 'Source-zone', 'CloseReason', 'Destination-zone', 'ModuleName',\n",
    "#         'ModuleBrief', 'RecieveInterface', 'Policy-name', 'IP-address', 'Source-address', 'Destination-address'\n",
    "#     ]\n",
    "\n",
    "#     # Replace specific values in Source-address and Destination-address\n",
    "#     df_logs['Source-address'] = df_logs['Source-address'].apply(lambda x: '0' if x.startswith('192.168') else x)\n",
    "#     df_logs['Destination-address'] = df_logs['Destination-address'].apply(lambda x: '0' if x.startswith('192.168') else x)\n",
    "\n",
    "#     # Apply LabelEncoder to each column in df_logs\n",
    "#     for col in cols_to_encode:\n",
    "#         label_encoder = label_mapping.get(col, LabelEncoder())\n",
    "#         df_logs[col] = label_encoder.fit_transform(df_logs[col])\n",
    "#         label_encoders[col] = label_encoder\n",
    "#         label_mapping[col] = label_encoder  # Update or add to the mapping\n",
    "\n",
    "#     # Save the label mappings for future use\n",
    "#     with open('label_mapping.pkl', 'wb') as f:\n",
    "#         pickle.dump(label_mapping, f)\n",
    "\n",
    "#     return df_logs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mapping the values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforming_columns(df_logs):\n",
    "    def read_mapping(column_name):\n",
    "        mapping_dir = 'mapping'\n",
    "        mapping_file = os.path.join(mapping_dir, f'{column_name}_mapping.txt')\n",
    "        if not os.path.exists(mapping_file):\n",
    "            os.makedirs(mapping_dir, exist_ok=True)\n",
    "            with open(mapping_file, 'w') as file:\n",
    "                file.write('{}')\n",
    "        with open(mapping_file, 'r') as file:\n",
    "            return eval(file.read())\n",
    "\n",
    "    def write_mapping(column_name, column_mapping):\n",
    "        mapping_dir = 'mapping'\n",
    "        mapping_file = os.path.join(mapping_dir, f'{column_name}_mapping.txt')\n",
    "        with open(mapping_file, 'w') as file:\n",
    "            file.write(str(column_mapping))\n",
    "\n",
    "    def transform_column(column_name):\n",
    "        column_mapping = read_mapping(column_name)\n",
    "        modified = False  # Flag to track if mapping has been modified\n",
    "\n",
    "        def assign_unique_number(value):\n",
    "            nonlocal column_mapping, modified\n",
    "            if value not in column_mapping:\n",
    "                unique_number = max(column_mapping.values()) + 1 if column_mapping else 0\n",
    "                column_mapping[value] = unique_number\n",
    "                modified = True  # Set flag when a new value is encountered\n",
    "            return column_mapping[value]\n",
    "\n",
    "        df_logs[column_name] = df_logs[column_name].apply(assign_unique_number)\n",
    "\n",
    "        # Write the mapping only if it has been modified\n",
    "        if modified:\n",
    "            write_mapping(column_name, column_mapping)\n",
    "\n",
    "    # Apply transformation to each column\n",
    "    columns_to_transform = [\n",
    "            'Attack', 'Category', 'DstLocation', 'Os', 'SignName', 'SrcLocation', 'Target',\n",
    "            'UserName', 'VSys', 'slot', 'Action', 'Policy', 'Profile', 'Protocol-Name',\n",
    "            'Application', 'Source-zone', 'CloseReason', 'Destination-zone', 'ModuleName',\n",
    "            'ModuleBrief', 'RecieveInterface', 'Policy-name'\n",
    "        ]\n",
    "    for column in columns_to_transform:\n",
    "        transform_column(column)\n",
    "    \n",
    "    return df_logs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# issues\n",
    "- Everytime new label ID assigned to every number, even if the number already had labeled\n",
    "- due to label one number again and again, will cause mis interpret by AI\n",
    "- We need to adopt some solution to label these values such a way that only new-upcomming value got new unique number, rest not...\n",
    "- currently IP's columns are changing alot, we need to make different from label technique\n",
    "- we need to adopt file handling way to store existing labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transforming IP-addresses for Unique No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_ip(ip):\n",
    "    if ip == '-':\n",
    "        return -1  # Label '-' as -1\n",
    "    elif ip.startswith('192.168'):\n",
    "        return 0  # IP starts with 192.168\n",
    "    else:\n",
    "        # Remove dots from IP and divide by a hardcoded value (e.g., 10^12)\n",
    "        return int(ip.replace('.', '')) / 1e12\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_values_and_convert_to_numeric1(df):\n",
    "    columns = [\n",
    "    'Cpu',\n",
    "    'Destination-vpn-id',\n",
    "    'EventNum',\n",
    "    'IPVer',\n",
    "    'MaxSpeed',\n",
    "    'Role',\n",
    "    'SignId',\n",
    "    'Source-vpn-id',\n",
    "    'Protocol-Number',\n",
    "    'TotalPackets',\n",
    "    'Destination-port',\n",
    "    'SendBytes',\n",
    "    'SendPkts',\n",
    "    'RcvBytes',\n",
    "    'RcvPkts',\n",
    "    'SyslogId',\n",
    "    'Severity',\n",
    "    'Priority'\n",
    "    ]\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(str)\n",
    "        df[col] = df[col].replace('-', '-0.1')\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def replace_values_and_convert_to_numeric2(df):\n",
    "\n",
    "#     columns = [\n",
    "#     'SendBytes',\n",
    "#     'SendPkts',\n",
    "#     'RcvBytes',\n",
    "#     'RcvPkts',\n",
    "#     'SyslogId'\n",
    "#     ]\n",
    "\n",
    "#     for col in columns:\n",
    "#         df[col] = df[col].astype(str)\n",
    "#         df[col] = df[col].replace('-', '0')\n",
    "#         df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_processed_time(df_logs):\n",
    "    # Replace '-' with a default date in ISO 8601 Zulu format\n",
    "    default_date = '1970-01-01T00:00:00.000Z'\n",
    "    df_logs['BeginTime'] = df_logs['BeginTime'].replace('-', default_date)\n",
    "    df_logs['EndTime'] = df_logs['EndTime'].replace('-', default_date)\n",
    "\n",
    "    # Convert 'EndTime' and 'BeginTime' columns to datetime format\n",
    "    df_logs['EndTime'] = pd.to_datetime(df_logs['EndTime'])\n",
    "    df_logs['BeginTime'] = pd.to_datetime(df_logs['BeginTime'])\n",
    "\n",
    "    # Calculate time difference in seconds and store in a new 'Processed' column\n",
    "    df_logs['Processed'] = (df_logs['EndTime'] - df_logs['BeginTime']).dt.total_seconds()\n",
    "\n",
    "    # Drop 'BeginTime' and 'EndTime' columns\n",
    "    df_logs = df_logs.drop(columns=['BeginTime', 'EndTime'])\n",
    "    return(df_logs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dig_timestamps(df_logs):\n",
    "    import pandas as pd\n",
    "\n",
    "    # Convert to datetime format (Zulu time format)\n",
    "    df_logs['@timestamp'] = pd.to_datetime(df_logs['@timestamp'])\n",
    "\n",
    "    # Extracting day of the week\n",
    "    df_logs['DayOfTheWeek'] = df_logs['@timestamp'].dt.dayofweek  # Numeric representation of day of the week (0 - Monday, 6 - Sunday)\n",
    "\n",
    "    # Extracting time of the day\n",
    "    bins = {\n",
    "        (0, 6): 0,      # Night\n",
    "        (6, 12): 1,     # Morning\n",
    "        (12, 18): 2,    # Afternoon\n",
    "        (18, 24): 3     # Evening\n",
    "    }\n",
    "    df_logs['DayOrNight'] = df_logs['@timestamp'].dt.hour.apply(lambda x: next((v for k, v in bins.items() if k[0] <= x < k[1]), 0))\n",
    "\n",
    "    # Extracting time bins\n",
    "    bins_labels = ['Late Night', 'Early Morning', 'Morning', 'Afternoon', 'Evening', 'Night']\n",
    "    bins_edges = [0, 4, 8, 12, 16, 20, 24]  # Customize as needed\n",
    "    df_logs['TimeBins'] = pd.cut(df_logs['@timestamp'].dt.hour, bins=bins_edges, labels=False)\n",
    "\n",
    "    df_logs = df_logs.drop(columns=['@timestamp'])\n",
    "    return(df_logs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_db(df_logs):\n",
    "    import pandas as pd\n",
    "    import sqlite3\n",
    "\n",
    "    # Assuming df_logs is your DataFrame containing the data you want to append to the SQL database\n",
    "    # And the database file is 'seam_logs.db'\n",
    "\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect('seam_logs.db')\n",
    "\n",
    "    # Append the data from df_logs to the SQL database table 'seam_table'\n",
    "    df_logs.to_sql('seam_table', conn, if_exists='append', index=False)\n",
    "\n",
    "    # Commit changes and close connection\n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan(df_logs):\n",
    "    global DF\n",
    "    # Check for NaN, null, or inf in the entire DataFrame\n",
    "    problematic_values = df_logs.isnull().values.any() or df_logs.isna().values.any() or df_logs.isin([np.inf, -np.inf]).values.any()\n",
    "\n",
    "    if problematic_values:\n",
    "        print(\"The DataFrame contains NaN, null, or infinite values.\")\n",
    "    else:\n",
    "        print(\"The DataFrame does not contain NaN, null, or infinite values.\")\n",
    "        from sklearn.cluster import DBSCAN\n",
    "\n",
    "        # Assuming df2 contains your DataFrame with all the columns\n",
    "        X = df_logs.values  # Using all columns as features\n",
    "\n",
    "        # Initialize DBSCAN\n",
    "        dbscan = DBSCAN(eps=0.5, min_samples=5)  # Adjust parameters as needed\n",
    "\n",
    "        # Fit DBSCAN to your data\n",
    "        dbscan.fit(X)\n",
    "\n",
    "        # Retrieve cluster labels and outliers\n",
    "        labels = dbscan.labels_\n",
    "        outliers = df_logs[labels == -1]  # Outliers are labeled as -1\n",
    "        DF['dbscan'] = dbscan.labels_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# added a dbscan() for clustering new upcomming log's data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also appended in the DB datarame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database already exists.\n",
      "The following columns are missing: Category, DstLocation, EventNum, Os, Role, SignId, SignName, SrcLocation, Target\n",
      "The DataFrame does not contain NaN, null, or infinite values.\n",
      "--- 0.03399777412414551 seconds ---\n"
     ]
    }
   ],
   "source": [
    "create_db()#1\n",
    "df_logs=add_new_time_values().copy()#2\n",
    "df_logs=filter_required_cols(df_logs).copy()#3\n",
    "df_logs = df_logs.applymap(clean_value_special_symbols)#4\n",
    "# df_logs=label_encoding(df_logs).copy()#5\n",
    "# Applying transformation to the 'Destination-address' column\n",
    "df_logs['Destination-address'] = df_logs['Destination-address'].apply(transform_ip)\n",
    "df_logs['Source-address'] = df_logs['Source-address'].apply(transform_ip)\n",
    "# df_logs['IP-address'] = df_logs['IP-address'].apply(transform_ip)#removing it since it has very different information rather then destination and source address\n",
    "df_logs = transforming_columns(df_logs).copy()#6\n",
    "\n",
    "replace_values_and_convert_to_numeric1(df_logs)#6\n",
    "# replace_values_and_convert_to_numeric2(df_logs)#7\n",
    "df_logs=find_processed_time(df_logs).copy()#8\n",
    "df_logs=dig_timestamps(df_logs).copy()#9\n",
    "# append_db(df_logs)#10\n",
    "\n",
    "#finding time to process below function\n",
    "import time\n",
    "start_time = time.time()\n",
    "dbscan(df_logs)#11\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rtrying to add in ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>Policy-name.keyword</th>\n",
       "      <th>ModuleName</th>\n",
       "      <th>Protocol-Name.keyword</th>\n",
       "      <th>Source-port</th>\n",
       "      <th>Time</th>\n",
       "      <th>Protocol-Number</th>\n",
       "      <th>HostName.keyword</th>\n",
       "      <th>host.ip</th>\n",
       "      <th>host.ip.keyword</th>\n",
       "      <th>...</th>\n",
       "      <th>Attack.keyword</th>\n",
       "      <th>MaxSpeed</th>\n",
       "      <th>TotalPackets</th>\n",
       "      <th>RecieveInterface.keyword</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Cpu.keyword</th>\n",
       "      <th>slot.keyword</th>\n",
       "      <th>application-name</th>\n",
       "      <th>application-name.keyword</th>\n",
       "      <th>dbscan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tNX6r4wBX92f7DaOi5Py</td>\n",
       "      <td>[Wifi-1_to_Internet.\u0000]</td>\n",
       "      <td>[POLICY]</td>\n",
       "      <td>[TCP]</td>\n",
       "      <td>[38133]</td>\n",
       "      <td>[2023-12-28T05:30:24.000Z]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s9X6r4wBX92f7DaOi5Py</td>\n",
       "      <td>[LAN-1_to_VMs.\u0000]</td>\n",
       "      <td>[POLICY]</td>\n",
       "      <td>[UDP]</td>\n",
       "      <td>[52761]</td>\n",
       "      <td>[2023-12-28T05:30:24.000Z]</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LaL6r4wBC4-Y0Pl2ixHw</td>\n",
       "      <td>[LAN-2_to_Internet]</td>\n",
       "      <td>[SECLOG]</td>\n",
       "      <td>[TCP]</td>\n",
       "      <td>[62462]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R2H6r4wBPF9qFOBui3Ts</td>\n",
       "      <td>[Wifi-1_to_VMs.\u0000]</td>\n",
       "      <td>[POLICY]</td>\n",
       "      <td>[UDP]</td>\n",
       "      <td>[50583]</td>\n",
       "      <td>[2023-12-28T05:30:24.000Z]</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RmH6r4wBPF9qFOBui3Ts</td>\n",
       "      <td>[Wifi-1_to_VMs.\u0000]</td>\n",
       "      <td>[POLICY]</td>\n",
       "      <td>[UDP]</td>\n",
       "      <td>[52383]</td>\n",
       "      <td>[2023-12-28T05:30:24.000Z]</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>OV74r4wBiXstdpQhvI4R</td>\n",
       "      <td>[LAN-2_to_Internet]</td>\n",
       "      <td>[SECLOG]</td>\n",
       "      <td>[TCP]</td>\n",
       "      <td>[50014]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>g0f4r4wBlEEDCPw3u4_w</td>\n",
       "      <td>[Wifi-1_to_Internet.\u0000]</td>\n",
       "      <td>[POLICY]</td>\n",
       "      <td>[TCP]</td>\n",
       "      <td>[52731]</td>\n",
       "      <td>[2023-12-28T05:28:25.000Z]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>dGH4r4wBPF9qFOBuu3HI</td>\n",
       "      <td>[Wifi-1_to_Internet]</td>\n",
       "      <td>[SECLOG]</td>\n",
       "      <td>[TCP]</td>\n",
       "      <td>[52661]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>C9X4r4wBX92f7DaOu0i-</td>\n",
       "      <td>[default.\u0000]</td>\n",
       "      <td>[POLICY]</td>\n",
       "      <td>[UDP]</td>\n",
       "      <td>[38514]</td>\n",
       "      <td>[2023-12-28T05:28:25.000Z]</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>6aH4r4wBC4-Y0Pl2u8a-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[DLP]</td>\n",
       "      <td>[TCP]</td>\n",
       "      <td>[57590]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2899 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       _id     Policy-name.keyword ModuleName  \\\n",
       "0     tNX6r4wBX92f7DaOi5Py  [Wifi-1_to_Internet.\u0000]   [POLICY]   \n",
       "1     s9X6r4wBX92f7DaOi5Py        [LAN-1_to_VMs.\u0000]   [POLICY]   \n",
       "2     LaL6r4wBC4-Y0Pl2ixHw     [LAN-2_to_Internet]   [SECLOG]   \n",
       "3     R2H6r4wBPF9qFOBui3Ts       [Wifi-1_to_VMs.\u0000]   [POLICY]   \n",
       "4     RmH6r4wBPF9qFOBui3Ts       [Wifi-1_to_VMs.\u0000]   [POLICY]   \n",
       "...                    ...                     ...        ...   \n",
       "2894  OV74r4wBiXstdpQhvI4R     [LAN-2_to_Internet]   [SECLOG]   \n",
       "2895  g0f4r4wBlEEDCPw3u4_w  [Wifi-1_to_Internet.\u0000]   [POLICY]   \n",
       "2896  dGH4r4wBPF9qFOBuu3HI    [Wifi-1_to_Internet]   [SECLOG]   \n",
       "2897  C9X4r4wBX92f7DaOu0i-             [default.\u0000]   [POLICY]   \n",
       "2898  6aH4r4wBC4-Y0Pl2u8a-                     NaN      [DLP]   \n",
       "\n",
       "     Protocol-Name.keyword Source-port                        Time  \\\n",
       "0                    [TCP]     [38133]  [2023-12-28T05:30:24.000Z]   \n",
       "1                    [UDP]     [52761]  [2023-12-28T05:30:24.000Z]   \n",
       "2                    [TCP]     [62462]                         NaN   \n",
       "3                    [UDP]     [50583]  [2023-12-28T05:30:24.000Z]   \n",
       "4                    [UDP]     [52383]  [2023-12-28T05:30:24.000Z]   \n",
       "...                    ...         ...                         ...   \n",
       "2894                 [TCP]     [50014]                         NaN   \n",
       "2895                 [TCP]     [52731]  [2023-12-28T05:28:25.000Z]   \n",
       "2896                 [TCP]     [52661]                         NaN   \n",
       "2897                 [UDP]     [38514]  [2023-12-28T05:28:25.000Z]   \n",
       "2898                 [TCP]     [57590]                         NaN   \n",
       "\n",
       "     Protocol-Number        HostName.keyword          host.ip  \\\n",
       "0                [6]  [Lynx-Huawei-USG6500E]  [192.168.0.254]   \n",
       "1               [17]  [Lynx-Huawei-USG6500E]  [192.168.0.254]   \n",
       "2                NaN  [Lynx-Huawei-USG6500E]  [192.168.0.254]   \n",
       "3               [17]  [Lynx-Huawei-USG6500E]  [192.168.0.254]   \n",
       "4               [17]  [Lynx-Huawei-USG6500E]  [192.168.0.254]   \n",
       "...              ...                     ...              ...   \n",
       "2894             NaN  [Lynx-Huawei-USG6500E]  [192.168.0.254]   \n",
       "2895             [6]  [Lynx-Huawei-USG6500E]  [192.168.0.254]   \n",
       "2896             NaN  [Lynx-Huawei-USG6500E]  [192.168.0.254]   \n",
       "2897            [17]  [Lynx-Huawei-USG6500E]  [192.168.0.254]   \n",
       "2898             NaN  [Lynx-Huawei-USG6500E]  [192.168.0.254]   \n",
       "\n",
       "      host.ip.keyword  ... Attack.keyword MaxSpeed TotalPackets  \\\n",
       "0     [192.168.0.254]  ...            NaN      NaN          NaN   \n",
       "1     [192.168.0.254]  ...            NaN      NaN          NaN   \n",
       "2     [192.168.0.254]  ...            NaN      NaN          NaN   \n",
       "3     [192.168.0.254]  ...            NaN      NaN          NaN   \n",
       "4     [192.168.0.254]  ...            NaN      NaN          NaN   \n",
       "...               ...  ...            ...      ...          ...   \n",
       "2894  [192.168.0.254]  ...            NaN      NaN          NaN   \n",
       "2895  [192.168.0.254]  ...            NaN      NaN          NaN   \n",
       "2896  [192.168.0.254]  ...            NaN      NaN          NaN   \n",
       "2897  [192.168.0.254]  ...            NaN      NaN          NaN   \n",
       "2898  [192.168.0.254]  ...            NaN      NaN          NaN   \n",
       "\n",
       "     RecieveInterface.keyword Attack Cpu.keyword slot.keyword  \\\n",
       "0                         NaN    NaN         NaN          NaN   \n",
       "1                         NaN    NaN         NaN          NaN   \n",
       "2                         NaN    NaN         NaN          NaN   \n",
       "3                         NaN    NaN         NaN          NaN   \n",
       "4                         NaN    NaN         NaN          NaN   \n",
       "...                       ...    ...         ...          ...   \n",
       "2894                      NaN    NaN         NaN          NaN   \n",
       "2895                      NaN    NaN         NaN          NaN   \n",
       "2896                      NaN    NaN         NaN          NaN   \n",
       "2897                      NaN    NaN         NaN          NaN   \n",
       "2898                      NaN    NaN         NaN          NaN   \n",
       "\n",
       "     application-name application-name.keyword dbscan  \n",
       "0                 NaN                      NaN      0  \n",
       "1                 NaN                      NaN      1  \n",
       "2                 NaN                      NaN     -1  \n",
       "3                 NaN                      NaN      2  \n",
       "4                 NaN                      NaN      2  \n",
       "...               ...                      ...    ...  \n",
       "2894              NaN                      NaN     -1  \n",
       "2895              NaN                      NaN      0  \n",
       "2896              NaN                      NaN     -1  \n",
       "2897              NaN                      NaN     17  \n",
       "2898              NaN                      NaN     -1  \n",
       "\n",
       "[2899 rows x 92 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['log_id', 'Policy-name.keyword', 'ModuleName', 'Protocol-Name.keyword',\n",
       "       'Source-port', 'Time', 'Protocol-Number', 'HostName.keyword', 'host.ip',\n",
       "       'host.ip.keyword', 'Source-address.keyword', 'ModuleBrief', '@version',\n",
       "       'Destination-port', 'Policy-name', 'Protocol-Name', 'HostName',\n",
       "       'Source-zone', 'VSys.keyword', 'event.original', 'Priority',\n",
       "       '@version.keyword', 'Severity', 'Destination-address.keyword',\n",
       "       'message', 'Destination-zone.keyword', 'Source-address',\n",
       "       'Source-port.keyword', '@timestamp', 'Destination-zone',\n",
       "       'Destination-address', 'ModuleName.keyword', 'message.keyword',\n",
       "       'Destination-port.keyword', 'ModuleBrief.keyword', 'Priority.keyword',\n",
       "       'Source-zone.keyword', 'VSys', 'BeginTime', 'CloseReason',\n",
       "       'Source-nat-port', 'Source-vpn-id.keyword', 'ApplicationName.keyword',\n",
       "       'SendPkts', 'EndTime', 'RcvPkts', 'Source-nat-port.keyword',\n",
       "       'SendBytes', 'IPVer', 'Source-vpn-id', 'ApplicationName',\n",
       "       'CloseReason.keyword', 'IPVer.keyword', 'Destination-vpn-id.keyword',\n",
       "       'Source-nat-address.keyword', 'Destination-vpn-id', 'RcvBytes',\n",
       "       'Source-nat-address', 'Policy', 'Direction.keyword', 'Action.keyword',\n",
       "       'Profile.keyword', 'Application', 'UserName.keyword', 'Action',\n",
       "       'SyslogId', 'Policy.keyword', 'FileName', 'Direction', 'Profile',\n",
       "       'FileName.keyword', 'FileType.keyword', 'UserName', 'SyslogId.keyword',\n",
       "       'FileType', 'Application.keyword', 'Cpu', 'slot', 'IP-address.keyword',\n",
       "       'IP-address', 'RecieveInterface', 'MaxSpeed.keyword', 'Attack.keyword',\n",
       "       'MaxSpeed', 'TotalPackets', 'RecieveInterface.keyword', 'Attack',\n",
       "       'Cpu.keyword', 'slot.keyword', 'application-name',\n",
       "       'application-name.keyword', 'dbscan'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting elasticsearch_dsl\n",
      "  Downloading elasticsearch_dsl-8.11.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\program files\\python37\\lib\\site-packages (from elasticsearch_dsl) (2.8.2)\n",
      "Requirement already satisfied: elasticsearch<9.0.0,>=8.0.0 in c:\\users\\zeeshan\\appdata\\roaming\\python\\python37\\site-packages (from elasticsearch_dsl) (8.11.1)\n",
      "Requirement already satisfied: elastic-transport<9,>=8 in c:\\users\\zeeshan\\appdata\\roaming\\python\\python37\\site-packages (from elasticsearch<9.0.0,>=8.0.0->elasticsearch_dsl) (8.10.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\program files\\python37\\lib\\site-packages (from python-dateutil->elasticsearch_dsl) (1.15.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in c:\\users\\zeeshan\\appdata\\roaming\\python\\python37\\site-packages (from elastic-transport<9,>=8->elasticsearch<9.0.0,>=8.0.0->elasticsearch_dsl) (1.26.16)\n",
      "Requirement already satisfied: certifi in c:\\users\\zeeshan\\appdata\\roaming\\python\\python37\\site-packages (from elastic-transport<9,>=8->elasticsearch<9.0.0,>=8.0.0->elasticsearch_dsl) (2022.12.7)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\zeeshan\\appdata\\roaming\\python\\python37\\site-packages (from elastic-transport<9,>=8->elasticsearch<9.0.0,>=8.0.0->elasticsearch_dsl) (4.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\zeeshan\\appdata\\roaming\\python\\python37\\site-packages (from importlib-metadata->elastic-transport<9,>=8->elasticsearch<9.0.0,>=8.0.0->elasticsearch_dsl) (3.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\zeeshan\\appdata\\roaming\\python\\python37\\site-packages (from importlib-metadata->elastic-transport<9,>=8->elasticsearch<9.0.0,>=8.0.0->elasticsearch_dsl) (4.7.1)\n",
      "Downloading elasticsearch_dsl-8.11.0-py3-none-any.whl (63 kB)\n",
      "   ---------------------------------------- 63.1/63.1 kB 562.0 kB/s eta 0:00:00\n",
      "Installing collected packages: elasticsearch_dsl\n",
      "Successfully installed elasticsearch_dsl-8.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install elasticsearch_dsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking the connection is establish or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch connection successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python37\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: The 'http_auth' parameter is deprecated. Use 'basic_auth' or 'bearer_auth' parameters instead\n",
      "  if __name__ == \"__main__\":\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Your Elasticsearch details\n",
    "ELASTICSEARCH_URL = \"https://192.168.7.2:9200\"\n",
    "ES_USERNAME = \"elastic\"\n",
    "ES_PASSWORD = \"ncsael@123\"\n",
    "\n",
    "# Create an Elasticsearch connection\n",
    "es_client = Elasticsearch([ELASTICSEARCH_URL], http_auth=(ES_USERNAME, ES_PASSWORD), verify_certs=False)\n",
    "\n",
    "# Check the connection\n",
    "if es_client.ping():\n",
    "    print(\"Elasticsearch connection successful!\")\n",
    "else:\n",
    "    print(\"Unable to establish connection to Elasticsearch.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python37\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: The 'http_auth' parameter is deprecated. Use 'basic_auth' or 'bearer_auth' parameters instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "ename": "BulkIndexError",
     "evalue": "500 document(s) failed to index.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBulkIndexError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2368\\1194728405.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mhelpers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbulk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mes_client\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dbscan_table\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\elasticsearch\\helpers\\actions.py\u001b[0m in \u001b[0;36mbulk\u001b[1;34m(client, actions, stats_only, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"yield_ok\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     for ok, item in streaming_bulk(\n\u001b[1;32m--> 522\u001b[1;33m         \u001b[0mclient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_status\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_status\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m     ):\n\u001b[0;32m    524\u001b[0m         \u001b[1;31m# go through request-response pairs and detect failures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\elasticsearch\\helpers\\actions.py\u001b[0m in \u001b[0;36mstreaming_bulk\u001b[1;34m(client, actions, chunk_size, max_chunk_bytes, raise_on_error, expand_action_callback, raise_on_exception, max_retries, initial_backoff, max_backoff, yield_ok, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[0;32m    444\u001b[0m                         \u001b[0mignore_status\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m                         \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m                         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m                     ),\n\u001b[0;32m    448\u001b[0m                 ):\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\elasticsearch\\helpers\\actions.py\u001b[0m in \u001b[0;36m_process_bulk_chunk\u001b[1;34m(client, bulk_actions, bulk_data, raise_on_exception, raise_on_error, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mraise_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_on_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         )\n\u001b[1;32m--> 355\u001b[1;33m     \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\elasticsearch\\helpers\\actions.py\u001b[0m in \u001b[0;36m_process_bulk_chunk_success\u001b[1;34m(resp, bulk_data, ignore_status, raise_on_error)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mBulkIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{len(errors)} document(s) failed to index.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBulkIndexError\u001b[0m: 500 document(s) failed to index."
     ]
    }
   ],
   "source": [
    "# from elasticsearch import Elasticsearch\n",
    "# from elasticsearch import helpers\n",
    "# from elasticsearch_dsl import connections\n",
    "\n",
    "# # es_client = connections.create_connection(hosts=['http://localhost:9200/'])\n",
    "# ELASTICSEARCH_URL = \"https://192.168.7.2:9200\"\n",
    "# ES_USERNAME = \"elastic\"\n",
    "# ES_PASSWORD = \"ncsael@123\"\n",
    "\n",
    "# # Create an Elasticsearch connection\n",
    "# es_client = Elasticsearch([ELASTICSEARCH_URL], http_auth=(ES_USERNAME, ES_PASSWORD), verify_certs=False)\n",
    "\n",
    "# # def doc_generator(DF):\n",
    "# #     df_iter = DF.iterrows()\n",
    "# #     for index, document in df_iter:\n",
    "# #         yield {\n",
    "# #                 \"_index\": 'dbscan_table',\n",
    "# #                 \"_source\": document,\n",
    "# #             }\n",
    "# def doc_generator(DF, index_name):\n",
    "#     df_iter = DF.iterrows()\n",
    "#     for index, document in df_iter:\n",
    "#         yield {\n",
    "#             \"_index\": index_name,\n",
    "#             \"_source\": document.to_dict(),  # Convert the row to a dictionary\n",
    "#         }\n",
    "\n",
    "        \n",
    "# helpers.bulk(es_client, doc_generator(DF, \"dbscan_table\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# renaming cols's name to avoid conflict of ES default name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named 'DF'\n",
    "DF.rename(columns={\"_id\": \"log_id\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for just creating a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python37\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: The 'http_auth' parameter is deprecated. Use 'basic_auth' or 'bearer_auth' parameters instead\n",
      "  if __name__ == \"__main__\":\n",
      "c:\\Program Files\\Python37\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'error': {'root_cause': [{'type': 'index_not_found_exception', 'reason': 'no such index [logs_index]', 'index_uuid': '_na_', 'resource.type': 'index_or_alias', 'resource.id': 'logs_index', 'index': 'logs_index'}], 'type': 'index_not_found_exception', 'reason': 'no such index [logs_index]', 'index_uuid': '_na_', 'resource.type': 'index_or_alias', 'resource.id': 'logs_index', 'index': 'logs_index'}, 'status': 404})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Your Elasticsearch details\n",
    "ELASTICSEARCH_URL = \"https://192.168.7.2:9200\"\n",
    "ES_USERNAME = \"elastic\"\n",
    "ES_PASSWORD = \"ncsael@123\"\n",
    "\n",
    "# Create an Elasticsearch connection\n",
    "es_client = Elasticsearch([ELASTICSEARCH_URL], http_auth=(ES_USERNAME, ES_PASSWORD), verify_certs=False)\n",
    "\n",
    "# Index name to delete\n",
    "index_name = \"logs_index\"\n",
    "\n",
    "# Delete the existing index, if it exists\n",
    "es_client.indices.delete(index=index_name, ignore=[400, 404])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>Protocol-Name.keyword</th>\n",
       "      <th>BeginTime</th>\n",
       "      <th>host.ip.keyword</th>\n",
       "      <th>CloseReason</th>\n",
       "      <th>Policy-name</th>\n",
       "      <th>HostName</th>\n",
       "      <th>Source-nat-port</th>\n",
       "      <th>event.original</th>\n",
       "      <th>Source-vpn-id.keyword</th>\n",
       "      <th>...</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Cpu.keyword</th>\n",
       "      <th>slot.keyword</th>\n",
       "      <th>Direction.keyword</th>\n",
       "      <th>FileName</th>\n",
       "      <th>Direction</th>\n",
       "      <th>FileName.keyword</th>\n",
       "      <th>FileType.keyword</th>\n",
       "      <th>FileType</th>\n",
       "      <th>dbscan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u4_8r4wBj-9RMafbYDvU</td>\n",
       "      <td>[UDP]</td>\n",
       "      <td>[2023-12-28T10:31:49.000Z]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>[aged-out]</td>\n",
       "      <td>[VMs_to_Internet]</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>[44400]</td>\n",
       "      <td>[&lt;190&gt;2023-12-28 10:32:24 Lynx-Huawei-USG6500E...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uo_8r4wBj-9RMafbYDuG</td>\n",
       "      <td>[UDP]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[LAN-1_to_VMs.\u0000]</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;190&gt;Dec 28 2023 10:32:24 Lynx-Huawei-USG6500...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uY_8r4wBj-9RMafbYDsU</td>\n",
       "      <td>[UDP]</td>\n",
       "      <td>[2023-12-28T10:31:48.000Z]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>[aged-out]</td>\n",
       "      <td>[LAN-1_to_VMs]</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;190&gt;2023-12-28 10:32:24 Lynx-Huawei-USG6500E...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8178r4wBiXstdpQhXpDh</td>\n",
       "      <td>[TCP]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[LAN-1_to_Internet.\u0000]</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;190&gt;Dec 28 2023 10:32:24 Lynx-Huawei-USG6500...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8l78r4wBiXstdpQhXpBz</td>\n",
       "      <td>[TCP]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[LAN-1_to_Internet.\u0000]</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;190&gt;Dec 28 2023 10:32:24 Lynx-Huawei-USG6500...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>SGH6r4wBPF9qFOBujHTb</td>\n",
       "      <td>[TCP]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Wifi-1_to_Internet.\u0000]</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;190&gt;Dec 28 2023 10:30:25 Lynx-Huawei-USG6500...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>uF76r4wBiXstdpQhjI_a</td>\n",
       "      <td>[TCP]</td>\n",
       "      <td>[2023-12-28T10:29:14.000Z]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>[tcp-fin]</td>\n",
       "      <td>[Wifi-1_to_Internet]</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>[2860]</td>\n",
       "      <td>[&lt;190&gt;2023-12-28 10:30:25 Lynx-Huawei-USG6500E...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>QaL6r4wBC4-Y0Pl2jxLh</td>\n",
       "      <td>[TCP]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[LAN-1_to_Internet.\u0000]</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;190&gt;Dec 28 2023 10:30:25 Lynx-Huawei-USG6500...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>htX6r4wBX92f7DaOjpSk</td>\n",
       "      <td>[TCP]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[VMs_to_Internet.\u0000]</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;190&gt;Dec 28 2023 10:30:25 Lynx-Huawei-USG6500...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>JUf6r4wBlEEDCPw3jdZR</td>\n",
       "      <td>[TCP]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[default.\u0000]</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;190&gt;Dec 28 2023 10:30:25 Lynx-Huawei-USG6500...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1929 rows Ã— 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       _id Protocol-Name.keyword                   BeginTime  \\\n",
       "0     u4_8r4wBj-9RMafbYDvU                 [UDP]  [2023-12-28T10:31:49.000Z]   \n",
       "1     uo_8r4wBj-9RMafbYDuG                 [UDP]                         NaN   \n",
       "2     uY_8r4wBj-9RMafbYDsU                 [UDP]  [2023-12-28T10:31:48.000Z]   \n",
       "3     8178r4wBiXstdpQhXpDh                 [TCP]                         NaN   \n",
       "4     8l78r4wBiXstdpQhXpBz                 [TCP]                         NaN   \n",
       "...                    ...                   ...                         ...   \n",
       "1924  SGH6r4wBPF9qFOBujHTb                 [TCP]                         NaN   \n",
       "1925  uF76r4wBiXstdpQhjI_a                 [TCP]  [2023-12-28T10:29:14.000Z]   \n",
       "1926  QaL6r4wBC4-Y0Pl2jxLh                 [TCP]                         NaN   \n",
       "1927  htX6r4wBX92f7DaOjpSk                 [TCP]                         NaN   \n",
       "1928  JUf6r4wBlEEDCPw3jdZR                 [TCP]                         NaN   \n",
       "\n",
       "      host.ip.keyword CloseReason             Policy-name  \\\n",
       "0     [192.168.0.254]  [aged-out]       [VMs_to_Internet]   \n",
       "1     [192.168.0.254]         NaN        [LAN-1_to_VMs.\u0000]   \n",
       "2     [192.168.0.254]  [aged-out]          [LAN-1_to_VMs]   \n",
       "3     [192.168.0.254]         NaN   [LAN-1_to_Internet.\u0000]   \n",
       "4     [192.168.0.254]         NaN   [LAN-1_to_Internet.\u0000]   \n",
       "...               ...         ...                     ...   \n",
       "1924  [192.168.0.254]         NaN  [Wifi-1_to_Internet.\u0000]   \n",
       "1925  [192.168.0.254]   [tcp-fin]    [Wifi-1_to_Internet]   \n",
       "1926  [192.168.0.254]         NaN   [LAN-1_to_Internet.\u0000]   \n",
       "1927  [192.168.0.254]         NaN     [VMs_to_Internet.\u0000]   \n",
       "1928  [192.168.0.254]         NaN             [default.\u0000]   \n",
       "\n",
       "                    HostName Source-nat-port  \\\n",
       "0     [Lynx-Huawei-USG6500E]         [44400]   \n",
       "1     [Lynx-Huawei-USG6500E]             NaN   \n",
       "2     [Lynx-Huawei-USG6500E]             NaN   \n",
       "3     [Lynx-Huawei-USG6500E]             NaN   \n",
       "4     [Lynx-Huawei-USG6500E]             NaN   \n",
       "...                      ...             ...   \n",
       "1924  [Lynx-Huawei-USG6500E]             NaN   \n",
       "1925  [Lynx-Huawei-USG6500E]          [2860]   \n",
       "1926  [Lynx-Huawei-USG6500E]             NaN   \n",
       "1927  [Lynx-Huawei-USG6500E]             NaN   \n",
       "1928  [Lynx-Huawei-USG6500E]             NaN   \n",
       "\n",
       "                                         event.original Source-vpn-id.keyword  \\\n",
       "0     [<190>2023-12-28 10:32:24 Lynx-Huawei-USG6500E...                   [0]   \n",
       "1     [<190>Dec 28 2023 10:32:24 Lynx-Huawei-USG6500...                   NaN   \n",
       "2     [<190>2023-12-28 10:32:24 Lynx-Huawei-USG6500E...                   [0]   \n",
       "3     [<190>Dec 28 2023 10:32:24 Lynx-Huawei-USG6500...                   NaN   \n",
       "4     [<190>Dec 28 2023 10:32:24 Lynx-Huawei-USG6500...                   NaN   \n",
       "...                                                 ...                   ...   \n",
       "1924  [<190>Dec 28 2023 10:30:25 Lynx-Huawei-USG6500...                   NaN   \n",
       "1925  [<190>2023-12-28 10:30:25 Lynx-Huawei-USG6500E...                   [0]   \n",
       "1926  [<190>Dec 28 2023 10:30:25 Lynx-Huawei-USG6500...                   NaN   \n",
       "1927  [<190>Dec 28 2023 10:30:25 Lynx-Huawei-USG6500...                   NaN   \n",
       "1928  [<190>Dec 28 2023 10:30:25 Lynx-Huawei-USG6500...                   NaN   \n",
       "\n",
       "      ... Attack Cpu.keyword slot.keyword Direction.keyword FileName  \\\n",
       "0     ...    NaN         NaN          NaN               NaN      NaN   \n",
       "1     ...    NaN         NaN          NaN               NaN      NaN   \n",
       "2     ...    NaN         NaN          NaN               NaN      NaN   \n",
       "3     ...    NaN         NaN          NaN               NaN      NaN   \n",
       "4     ...    NaN         NaN          NaN               NaN      NaN   \n",
       "...   ...    ...         ...          ...               ...      ...   \n",
       "1924  ...    NaN         NaN          NaN               NaN      NaN   \n",
       "1925  ...    NaN         NaN          NaN               NaN      NaN   \n",
       "1926  ...    NaN         NaN          NaN               NaN      NaN   \n",
       "1927  ...    NaN         NaN          NaN               NaN      NaN   \n",
       "1928  ...    NaN         NaN          NaN               NaN      NaN   \n",
       "\n",
       "     Direction FileName.keyword FileType.keyword FileType dbscan  \n",
       "0          NaN              NaN              NaN      NaN     -1  \n",
       "1          NaN              NaN              NaN      NaN      0  \n",
       "2          NaN              NaN              NaN      NaN     -1  \n",
       "3          NaN              NaN              NaN      NaN      1  \n",
       "4          NaN              NaN              NaN      NaN      2  \n",
       "...        ...              ...              ...      ...    ...  \n",
       "1924       NaN              NaN              NaN      NaN      6  \n",
       "1925       NaN              NaN              NaN      NaN     -1  \n",
       "1926       NaN              NaN              NaN      NaN      1  \n",
       "1927       NaN              NaN              NaN      NaN     16  \n",
       "1928       NaN              NaN              NaN      NaN      4  \n",
       "\n",
       "[1929 rows x 90 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add table and add data for first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZEESHAN\\AppData\\Roaming\\Python\\Python37\\site-packages\\elasticsearch\\_sync\\client\\__init__.py:401: SecurityWarning: Connecting to 'https://192.168.7.2:9200' using TLS with verify_certs=False is insecure\n",
      "  **transport_kwargs,\n",
      "c:\\Program Files\\Python37\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: The 'http_auth' parameter is deprecated. Use 'basic_auth' or 'bearer_auth' parameters instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "BadRequestError(400, 'resource_already_exists_exception', 'index [logs_index5/k5eGIigFT76rtfQs8GpvRA] already exists')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2368\\2485079724.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# Create the index with the specified settings and mappings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mes_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_settings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# Assuming your DataFrame is named 'DF' and contains the 'log_id', 'dbscan', and '@timestamp' columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\elasticsearch\\_sync\\client\\utils.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    400\u001b[0m                         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m  \u001b[1;31m# type: ignore[return-value]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\elasticsearch\\_sync\\client\\indices.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, index, aliases, error_trace, filter_path, human, mappings, master_timeout, pretty, settings, timeout, wait_for_active_shards)\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[0m__headers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"content-type\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"application/json\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m         return self.perform_request(  # type: ignore[return-value]\n\u001b[1;32m--> 494\u001b[1;33m             \u001b[1;34m\"PUT\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m__path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m__query\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m__headers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m__body\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m         )\n\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\elasticsearch\\_sync\\client\\_base.py\u001b[0m in \u001b[0;36mperform_request\u001b[1;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;31m# so we take advantage of their transport options.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         return self._client.perform_request(\n\u001b[1;32m--> 390\u001b[1;33m             \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\elasticsearch\\_sync\\client\\_base.py\u001b[0m in \u001b[0;36mperform_request\u001b[1;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m             raise HTTP_EXCEPTIONS.get(meta.status, ApiError)(\n\u001b[1;32m--> 321\u001b[1;33m                 \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresp_body\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             )\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBadRequestError\u001b[0m: BadRequestError(400, 'resource_already_exists_exception', 'index [logs_index5/k5eGIigFT76rtfQs8GpvRA] already exists')"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "import pandas as pd\n",
    "\n",
    "# Your Elasticsearch details\n",
    "ELASTICSEARCH_URL = \"https://192.168.7.2:9200\"\n",
    "ES_USERNAME = \"elastic\"\n",
    "ES_PASSWORD = \"ncsael@123\"\n",
    "\n",
    "# Create an Elasticsearch connection\n",
    "es_client = Elasticsearch([ELASTICSEARCH_URL], http_auth=(ES_USERNAME, ES_PASSWORD), verify_certs=False)\n",
    "\n",
    "# Index name to create\n",
    "index_name = \"logs_index5\"\n",
    "\n",
    "# Define the index settings and mappings for log_id, dbscan, and @timestamp columns\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"log_id\": {\"type\": \"keyword\"},\n",
    "            \"dbscan\": {\"type\": \"integer\"},\n",
    "            \"@timestamp\": {\"type\": \"date\"}  # Define the @timestamp column here\n",
    "            # Add more fields and their types as needed\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create the index with the specified settings and mappings\n",
    "es_client.indices.create(index=index_name, body=index_settings)\n",
    "\n",
    "# Assuming your DataFrame is named 'DF' and contains the 'log_id', 'dbscan', and '@timestamp' columns\n",
    "# Replace 'DF' with your actual DataFrame variable\n",
    "def doc_generator(df):\n",
    "    for index, row in df.iterrows():\n",
    "        yield {\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": row[\"log_id\"],\n",
    "            \"_source\": {\n",
    "                \"log_id\": row[\"log_id\"],\n",
    "                \"dbscan\": int(row[\"dbscan\"]),\n",
    "                \"@timestamp\": row[\"@timestamp\"]  # Include the @timestamp column data here\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Index the DataFrame into Elasticsearch\n",
    "helpers.bulk(es_client, doc_generator(DF[[\"log_id\", \"dbscan\", \"@timestamp\"]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# append data in DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python37\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: The 'http_auth' parameter is deprecated. Use 'basic_auth' or 'bearer_auth' parameters instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1929, [])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "import pandas as pd\n",
    "\n",
    "# Your Elasticsearch details\n",
    "ELASTICSEARCH_URL = \"https://192.168.7.2:9200\"\n",
    "ES_USERNAME = \"elastic\"\n",
    "ES_PASSWORD = \"ncsael@123\"\n",
    "\n",
    "# Create an Elasticsearch connection\n",
    "es_client = Elasticsearch([ELASTICSEARCH_URL], http_auth=(ES_USERNAME, ES_PASSWORD), verify_certs=False)\n",
    "\n",
    "# Index name to append data\n",
    "index_name = \"logs_index5\"  # Use the existing index name\n",
    "\n",
    "# Assuming your DataFrame is named 'DF' and contains the 'log_id', 'dbscan', and '@timestamp' columns\n",
    "# Replace 'DF' with your actual DataFrame variable\n",
    "def doc_generator(df):\n",
    "    for index, row in df.iterrows():\n",
    "        yield {\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": row[\"log_id\"],\n",
    "            \"_source\": {\n",
    "                \"log_id\": row[\"log_id\"],\n",
    "                \"dbscan\": int(row[\"dbscan\"]),\n",
    "                \"@timestamp\": row[\"@timestamp\"]\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Index the DataFrame into the existing Elasticsearch index\n",
    "helpers.bulk(es_client, doc_generator(DF[[\"log_id\", \"dbscan\", \"@timestamp\"]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generic:\n",
    "\n",
    "- to check table already created, then append\n",
    "- if not already created table, then create and add data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python37\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: The 'http_auth' parameter is deprecated. Use 'basic_auth' or 'bearer_auth' parameters instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1428, [])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "import pandas as pd\n",
    "\n",
    "# Your Elasticsearch details\n",
    "ELASTICSEARCH_URL = \"https://192.168.7.2:9200\"\n",
    "ES_USERNAME = \"elastic\"\n",
    "ES_PASSWORD = \"ncsael@123\"\n",
    "\n",
    "# Create an Elasticsearch connection\n",
    "es_client = Elasticsearch([ELASTICSEARCH_URL], http_auth=(ES_USERNAME, ES_PASSWORD), verify_certs=False)\n",
    "\n",
    "# Index name to append data\n",
    "index_name = \"logs_index5\"  # Use the existing index name\n",
    "\n",
    "# Check if the index exists\n",
    "if not es_client.indices.exists(index=index_name):\n",
    "    # Define the index settings and mappings for log_id, dbscan, and @timestamp columns\n",
    "    index_settings = {\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"log_id\": {\"type\": \"keyword\"},\n",
    "                \"dbscan\": {\"type\": \"integer\"},\n",
    "                \"@timestamp\": {\"type\": \"date\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Create the index with the specified settings and mappings\n",
    "    es_client.indices.create(index=index_name, body=index_settings)\n",
    "\n",
    "# Assuming your DataFrame is named 'DF' and contains the 'log_id', 'dbscan', and '@timestamp' columns\n",
    "# Replace 'DF' with your actual DataFrame variable\n",
    "def doc_generator(df):\n",
    "    for index, row in df.iterrows():\n",
    "        yield {\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": row[\"log_id\"],\n",
    "            \"_source\": {\n",
    "                \"log_id\": row[\"log_id\"],\n",
    "                \"dbscan\": int(row[\"dbscan\"]),\n",
    "                \"@timestamp\": row[\"@timestamp\"]\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Index the DataFrame into the existing Elasticsearch index\n",
    "helpers.bulk(es_client, doc_generator(DF[[\"log_id\", \"dbscan\", \"@timestamp\"]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python37\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: The 'http_auth' parameter is deprecated. Use 'basic_auth' or 'bearer_auth' parameters instead\n",
      "  if __name__ == \"__main__\":\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "BadRequestError(400, 'mapper_parsing_exception', 'Field [_id] is defined more than once')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2368\\2280870189.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# Create the index with the specified settings and mappings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mes_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_settings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m# ... (Continue with indexing your DataFrame)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\elasticsearch\\_sync\\client\\utils.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    400\u001b[0m                         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m  \u001b[1;31m# type: ignore[return-value]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\elasticsearch\\_sync\\client\\indices.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, index, aliases, error_trace, filter_path, human, mappings, master_timeout, pretty, settings, timeout, wait_for_active_shards)\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[0m__headers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"content-type\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"application/json\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m         return self.perform_request(  # type: ignore[return-value]\n\u001b[1;32m--> 494\u001b[1;33m             \u001b[1;34m\"PUT\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m__path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m__query\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m__headers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m__body\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m         )\n\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\elasticsearch\\_sync\\client\\_base.py\u001b[0m in \u001b[0;36mperform_request\u001b[1;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;31m# so we take advantage of their transport options.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         return self._client.perform_request(\n\u001b[1;32m--> 390\u001b[1;33m             \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\elasticsearch\\_sync\\client\\_base.py\u001b[0m in \u001b[0;36mperform_request\u001b[1;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m             raise HTTP_EXCEPTIONS.get(meta.status, ApiError)(\n\u001b[1;32m--> 321\u001b[1;33m                 \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresp_body\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             )\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBadRequestError\u001b[0m: BadRequestError(400, 'mapper_parsing_exception', 'Field [_id] is defined more than once')"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Your Elasticsearch details\n",
    "ELASTICSEARCH_URL = \"https://192.168.7.2:9200\"\n",
    "ES_USERNAME = \"elastic\"\n",
    "ES_PASSWORD = \"ncsael@123\"\n",
    "\n",
    "# Create an Elasticsearch connection\n",
    "es_client = Elasticsearch([ELASTICSEARCH_URL], http_auth=(ES_USERNAME, ES_PASSWORD), verify_certs=False)\n",
    "\n",
    "# Index name to create or update\n",
    "index_name = \"logs_index\"\n",
    "\n",
    "# Check if the index exists before deleting it\n",
    "if es_client.indices.exists(index=index_name):\n",
    "    # Delete the existing index\n",
    "    es_client.indices.delete(index=index_name)\n",
    "\n",
    "# Define the index settings and mappings for _id and dbscan columns\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"_id\": {\"type\": \"keyword\"},\n",
    "            \"dbscan\": {\"type\": \"integer\"}\n",
    "            # Add more fields and their types as needed\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create the index with the specified settings and mappings\n",
    "es_client.indices.create(index=index_name, body=index_settings)\n",
    "\n",
    "# ... (Continue with indexing your DataFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python37\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: The 'http_auth' parameter is deprecated. Use 'basic_auth' or 'bearer_auth' parameters instead\n",
      "  if __name__ == \"__main__\":\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 3, 'timed_out': False, 'total': 0, 'deleted': 0, 'batches': 0, 'version_conflicts': 0, 'noops': 0, 'retries': {'bulk': 0, 'search': 0}, 'throttled_millis': 0, 'requests_per_second': -1.0, 'throttled_until_millis': 0, 'failures': []})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Your Elasticsearch details\n",
    "ELASTICSEARCH_URL = \"https://192.168.7.2:9200\"\n",
    "ES_USERNAME = \"elastic\"\n",
    "ES_PASSWORD = \"ncsael@123\"\n",
    "\n",
    "# Create an Elasticsearch connection\n",
    "es_client = Elasticsearch([ELASTICSEARCH_URL], http_auth=(ES_USERNAME, ES_PASSWORD), verify_certs=False)\n",
    "\n",
    "# Index name to delete data from\n",
    "index_name = \"logs_index\"\n",
    "\n",
    "# Define the query to match all documents in the index\n",
    "delete_query = {\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Delete all documents from the logs_index\n",
    "es_client.delete_by_query(index=index_name, body=delete_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame does not contain NaN, null, or infinite values.\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN, null, or inf in the entire DataFrame\n",
    "problematic_values = df_logs.isnull().values.any() or df_logs.isna().values.any() or df_logs.isin([np.inf, -np.inf]).values.any()\n",
    "\n",
    "if problematic_values:\n",
    "    print(\"The DataFrame contains NaN, null, or infinite values.\")\n",
    "else:\n",
    "    print(\"The DataFrame does not contain NaN, null, or infinite values.\")\n",
    "    from sklearn.cluster import DBSCAN\n",
    "\n",
    "    # Assuming df2 contains your DataFrame with all the columns\n",
    "    X = df_logs.values  # Using all columns as features\n",
    "\n",
    "    # Initialize DBSCAN\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=5)  # Adjust parameters as needed\n",
    "\n",
    "    # Fit DBSCAN to your data\n",
    "    dbscan.fit(X)\n",
    "\n",
    "    # Retrieve cluster labels and outliers\n",
    "    labels = dbscan.labels_\n",
    "    outliers = df_logs[labels == -1]  # Outliers are labeled as -1\n",
    "    DF['dbscan'] = dbscan.labels_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>Protocol-Name.keyword</th>\n",
       "      <th>BeginTime</th>\n",
       "      <th>host.ip.keyword</th>\n",
       "      <th>CloseReason</th>\n",
       "      <th>Policy-name</th>\n",
       "      <th>HostName</th>\n",
       "      <th>Source-nat-port</th>\n",
       "      <th>event.original</th>\n",
       "      <th>Source-vpn-id.keyword</th>\n",
       "      <th>...</th>\n",
       "      <th>RecieveInterface</th>\n",
       "      <th>MaxSpeed.keyword</th>\n",
       "      <th>Attack.keyword</th>\n",
       "      <th>MaxSpeed</th>\n",
       "      <th>TotalPackets</th>\n",
       "      <th>RecieveInterface.keyword</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Cpu.keyword</th>\n",
       "      <th>slot.keyword</th>\n",
       "      <th>dbscan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J2Hxr4wBPF9qFOBuaGJ9</td>\n",
       "      <td>[TCP]</td>\n",
       "      <td>[2023-12-28T10:20:08.000Z]</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>[tcp-rst]</td>\n",
       "      <td>[LAN-1_to_Internet]</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>[6911]</td>\n",
       "      <td>[&lt;190&gt;2023-12-28 10:20:24 Lynx-Huawei-USG6500E...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EV7xr4wBiXstdpQhaIIG</td>\n",
       "      <td>[TCP]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[LAN-1_to_Internet.\u0000]</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;190&gt;Dec 28 2023 10:20:24 Lynx-Huawei-USG6500...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JmHxr4wBPF9qFOBuZ2L_</td>\n",
       "      <td>[TCP]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[LAN-1_to_Internet.\u0000]</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;190&gt;Dec 28 2023 10:20:24 Lynx-Huawei-USG6500...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zkbxr4wBlEEDCPw3ZzTi</td>\n",
       "      <td>[TCP]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[LAN-1_to_Internet.\u0000]</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;190&gt;Dec 28 2023 10:20:24 Lynx-Huawei-USG6500...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zUbxr4wBlEEDCPw3ZzTi</td>\n",
       "      <td>[TCP]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[192.168.0.254]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[LAN-1_to_Internet.\u0000]</td>\n",
       "      <td>[Lynx-Huawei-USG6500E]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;190&gt;Dec 28 2023 10:20:24 Lynx-Huawei-USG6500...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    _id Protocol-Name.keyword                   BeginTime  \\\n",
       "0  J2Hxr4wBPF9qFOBuaGJ9                 [TCP]  [2023-12-28T10:20:08.000Z]   \n",
       "1  EV7xr4wBiXstdpQhaIIG                 [TCP]                         NaN   \n",
       "2  JmHxr4wBPF9qFOBuZ2L_                 [TCP]                         NaN   \n",
       "3  zkbxr4wBlEEDCPw3ZzTi                 [TCP]                         NaN   \n",
       "4  zUbxr4wBlEEDCPw3ZzTi                 [TCP]                         NaN   \n",
       "\n",
       "   host.ip.keyword CloseReason            Policy-name                HostName  \\\n",
       "0  [192.168.0.254]   [tcp-rst]    [LAN-1_to_Internet]  [Lynx-Huawei-USG6500E]   \n",
       "1  [192.168.0.254]         NaN  [LAN-1_to_Internet.\u0000]  [Lynx-Huawei-USG6500E]   \n",
       "2  [192.168.0.254]         NaN  [LAN-1_to_Internet.\u0000]  [Lynx-Huawei-USG6500E]   \n",
       "3  [192.168.0.254]         NaN  [LAN-1_to_Internet.\u0000]  [Lynx-Huawei-USG6500E]   \n",
       "4  [192.168.0.254]         NaN  [LAN-1_to_Internet.\u0000]  [Lynx-Huawei-USG6500E]   \n",
       "\n",
       "  Source-nat-port                                     event.original  \\\n",
       "0          [6911]  [<190>2023-12-28 10:20:24 Lynx-Huawei-USG6500E...   \n",
       "1             NaN  [<190>Dec 28 2023 10:20:24 Lynx-Huawei-USG6500...   \n",
       "2             NaN  [<190>Dec 28 2023 10:20:24 Lynx-Huawei-USG6500...   \n",
       "3             NaN  [<190>Dec 28 2023 10:20:24 Lynx-Huawei-USG6500...   \n",
       "4             NaN  [<190>Dec 28 2023 10:20:24 Lynx-Huawei-USG6500...   \n",
       "\n",
       "  Source-vpn-id.keyword  ... RecieveInterface MaxSpeed.keyword Attack.keyword  \\\n",
       "0                   [0]  ...              NaN              NaN            NaN   \n",
       "1                   NaN  ...              NaN              NaN            NaN   \n",
       "2                   NaN  ...              NaN              NaN            NaN   \n",
       "3                   NaN  ...              NaN              NaN            NaN   \n",
       "4                   NaN  ...              NaN              NaN            NaN   \n",
       "\n",
       "  MaxSpeed TotalPackets RecieveInterface.keyword Attack Cpu.keyword  \\\n",
       "0      NaN          NaN                      NaN    NaN         NaN   \n",
       "1      NaN          NaN                      NaN    NaN         NaN   \n",
       "2      NaN          NaN                      NaN    NaN         NaN   \n",
       "3      NaN          NaN                      NaN    NaN         NaN   \n",
       "4      NaN          NaN                      NaN    NaN         NaN   \n",
       "\n",
       "  slot.keyword dbscan  \n",
       "0          NaN     -1  \n",
       "1          NaN      0  \n",
       "2          NaN      0  \n",
       "3          NaN      0  \n",
       "4          NaN      0  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'Protocol-Name.keyword', 'BeginTime', 'host.ip.keyword',\n",
       "       'CloseReason', 'Policy-name', 'HostName', 'event.original',\n",
       "       'Source-vpn-id.keyword', 'Priority', '@version.keyword',\n",
       "       'ApplicationName.keyword', 'SendPkts', 'Source-address',\n",
       "       'Source-port.keyword', 'ModuleName.keyword', 'ModuleBrief.keyword',\n",
       "       'Priority.keyword', 'Source-zone.keyword', 'Policy-name.keyword',\n",
       "       'EndTime', 'ModuleName', 'Source-port', 'HostName.keyword', 'RcvPkts',\n",
       "       'SendBytes', 'host.ip', 'Source-address.keyword', 'IPVer',\n",
       "       'ModuleBrief', '@version', 'Destination-port', 'Source-vpn-id',\n",
       "       'Protocol-Name', 'Source-zone', 'ApplicationName',\n",
       "       'CloseReason.keyword', 'IPVer.keyword', 'Destination-vpn-id.keyword',\n",
       "       'Severity', 'Destination-address.keyword', 'message',\n",
       "       'Destination-zone.keyword', '@timestamp', 'Destination-zone',\n",
       "       'Destination-address', 'Destination-port.keyword', 'Destination-vpn-id',\n",
       "       'RcvBytes', 'Time', 'Protocol-Number', 'VSys.keyword',\n",
       "       'message.keyword', 'VSys', 'Source-nat-port', 'Source-nat-port.keyword',\n",
       "       'Source-nat-address.keyword', 'Source-nat-address', 'Policy',\n",
       "       'Direction.keyword', 'Action.keyword', 'Profile.keyword', 'Application',\n",
       "       'UserName.keyword', 'Action', 'SyslogId', 'Policy.keyword', 'FileName',\n",
       "       'Direction', 'Profile', 'FileName.keyword', 'FileType.keyword',\n",
       "       'UserName', 'SyslogId.keyword', 'FileType', 'Application.keyword',\n",
       "       'application-name', 'application-name.keyword', 'Cpu', 'slot',\n",
       "       'IP-address.keyword', 'IP-address', 'RecieveInterface',\n",
       "       'MaxSpeed.keyword', 'Attack.keyword', 'MaxSpeed', 'TotalPackets',\n",
       "       'RecieveInterface.keyword', 'Attack', 'Cpu.keyword', 'slot.keyword'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5401 entries, 0 to 5400\n",
      "Data columns (total 46 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Action               5401 non-null   int64  \n",
      " 1   Application          5401 non-null   int64  \n",
      " 2   Attack               5401 non-null   int64  \n",
      " 3   Category             5401 non-null   int64  \n",
      " 4   CloseReason          5401 non-null   int64  \n",
      " 5   Cpu                  5401 non-null   float64\n",
      " 6   Destination-address  5401 non-null   float64\n",
      " 7   Destination-port     5401 non-null   float64\n",
      " 8   Destination-vpn-id   5401 non-null   float64\n",
      " 9   Destination-zone     5401 non-null   int64  \n",
      " 10  DstLocation          5401 non-null   int64  \n",
      " 11  EventNum             5401 non-null   float64\n",
      " 12  IPVer                5401 non-null   float64\n",
      " 13  MaxSpeed             5401 non-null   float64\n",
      " 14  ModuleBrief          5401 non-null   int64  \n",
      " 15  ModuleName           5401 non-null   int64  \n",
      " 16  Os                   5401 non-null   int64  \n",
      " 17  Policy               5401 non-null   int64  \n",
      " 18  Policy-name          5401 non-null   int64  \n",
      " 19  Priority             5401 non-null   int64  \n",
      " 20  Profile              5401 non-null   int64  \n",
      " 21  Protocol-Name        5401 non-null   int64  \n",
      " 22  Protocol-Number      5401 non-null   float64\n",
      " 23  RcvBytes             5401 non-null   float64\n",
      " 24  RcvPkts              5401 non-null   float64\n",
      " 25  RecieveInterface     5401 non-null   int64  \n",
      " 26  Role                 5401 non-null   float64\n",
      " 27  SendBytes            5401 non-null   float64\n",
      " 28  SendPkts             5401 non-null   float64\n",
      " 29  Severity             5401 non-null   int64  \n",
      " 30  SignId               5401 non-null   float64\n",
      " 31  SignName             5401 non-null   int64  \n",
      " 32  Source-address       5401 non-null   int64  \n",
      " 33  Source-vpn-id        5401 non-null   float64\n",
      " 34  Source-zone          5401 non-null   int64  \n",
      " 35  SrcLocation          5401 non-null   int64  \n",
      " 36  SyslogId             5401 non-null   float64\n",
      " 37  Target               5401 non-null   int64  \n",
      " 38  TotalPackets         5401 non-null   float64\n",
      " 39  UserName             5401 non-null   int64  \n",
      " 40  VSys                 5401 non-null   int64  \n",
      " 41  slot                 5401 non-null   int64  \n",
      " 42  Processed            5401 non-null   float64\n",
      " 43  DayOfTheWeek         5401 non-null   int64  \n",
      " 44  DayOrNight           5401 non-null   int64  \n",
      " 45  TimeBins             5401 non-null   int64  \n",
      "dtypes: float64(18), int64(28)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "df_logs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os  # Import os module to check file existence\n",
    "\n",
    "# # Sample DataFrame with 'Attack' column\n",
    "\n",
    "\n",
    "# # Check if the file exists or it's the first run\n",
    "# if not os.path.exists('attack_mapping.txt'):\n",
    "#     with open('attack_mapping.txt', 'w') as file:\n",
    "#         file.write('{}')  # Initialize an empty dictionary in the file\n",
    "\n",
    "# # Load or initialize dictionary from a file\n",
    "# with open('attack_mapping.txt', 'r') as file:\n",
    "#     attack_mapping = eval(file.read())  # Read the stored dictionary\n",
    "\n",
    "# def assign_unique_number(value):\n",
    "#     global attack_mapping\n",
    "#     if value not in attack_mapping:\n",
    "#         # Assign a new unique number for the new value\n",
    "#         unique_number = max(attack_mapping.values()) + 1 if attack_mapping else 0\n",
    "#         attack_mapping[value] = unique_number\n",
    "#         # Update the file with the new mapping\n",
    "#         with open('attack_mapping.txt', 'w') as file:\n",
    "#             file.write(str(attack_mapping))  # Store the updated dictionary in the file\n",
    "\n",
    "#     return attack_mapping[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Applying transformation to the 'Attack' column\n",
    "# df_logs['Attack-encoded'] = df_logs['Attack'].apply(assign_unique_number)\n",
    "\n",
    "# # print(df_logs)\n",
    "# # Saving transformed DataFrame to a CSV file\n",
    "# df_logs.to_csv('transformed_output.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving to csv\n",
    "df_logs.to_csv('transformed_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3264 entries, 0 to 3263\n",
      "Data columns (total 46 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   @timestamp           3264 non-null   object \n",
      " 1   Action               3264 non-null   int64  \n",
      " 2   Application          3264 non-null   int64  \n",
      " 3   Attack               3264 non-null   int64  \n",
      " 4   BeginTime            3264 non-null   object \n",
      " 5   Category             3264 non-null   int64  \n",
      " 6   CloseReason          3264 non-null   int64  \n",
      " 7   Cpu                  3264 non-null   object \n",
      " 8   Destination-address  3264 non-null   float64\n",
      " 9   Destination-port     3264 non-null   object \n",
      " 10  Destination-vpn-id   3264 non-null   object \n",
      " 11  Destination-zone     3264 non-null   int64  \n",
      " 12  DstLocation          3264 non-null   int64  \n",
      " 13  EndTime              3264 non-null   object \n",
      " 14  EventNum             3264 non-null   object \n",
      " 15  IP-address           3264 non-null   object \n",
      " 16  IPVer                3264 non-null   object \n",
      " 17  MaxSpeed             3264 non-null   object \n",
      " 18  ModuleBrief          3264 non-null   int64  \n",
      " 19  ModuleName           3264 non-null   int64  \n",
      " 20  Os                   3264 non-null   int64  \n",
      " 21  Policy               3264 non-null   int64  \n",
      " 22  Policy-name          3264 non-null   int64  \n",
      " 23  Priority             3264 non-null   object \n",
      " 24  Profile              3264 non-null   int64  \n",
      " 25  Protocol-Name        3264 non-null   int64  \n",
      " 26  Protocol-Number      3264 non-null   object \n",
      " 27  RcvBytes             3264 non-null   object \n",
      " 28  RcvPkts              3264 non-null   object \n",
      " 29  RecieveInterface     3264 non-null   int64  \n",
      " 30  Role                 3264 non-null   object \n",
      " 31  SendBytes            3264 non-null   object \n",
      " 32  SendPkts             3264 non-null   object \n",
      " 33  Severity             3264 non-null   object \n",
      " 34  SignId               3264 non-null   object \n",
      " 35  SignName             3264 non-null   int64  \n",
      " 36  Source-address       3264 non-null   int64  \n",
      " 37  Source-vpn-id        3264 non-null   object \n",
      " 38  Source-zone          3264 non-null   int64  \n",
      " 39  SrcLocation          3264 non-null   int64  \n",
      " 40  SyslogId             3264 non-null   object \n",
      " 41  Target               3264 non-null   int64  \n",
      " 42  TotalPackets         3264 non-null   object \n",
      " 43  UserName             3264 non-null   int64  \n",
      " 44  VSys                 3264 non-null   int64  \n",
      " 45  slot                 3264 non-null   int64  \n",
      "dtypes: float64(1), int64(23), object(22)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_logs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
